\SetPicSubDir{my-intro}

\chapter{Introduction}
\label{ch:introduction}

\vspace{2em}

\section{Computation-in-memory architecture}

There has been growing interest in neuromorphic computing to fuel the next generation of artificial intelligence. As such, there is high demand for faster computational power not only for deploying but also for training \ac{ANN} models. Widely used digital computers implement the von Neumann architecture where computation and memory units are separate. It is found that the transferring of data between the computing and memory storage takes up the majority of the \acs{CPU} time which not only limits the maximum speed achievable but also consumes 100 times more power in comparison to the actual floating-point computation itself \cite{Zou_Xu_Chen_Yan_Han_2021}. This has given rise to the von Neumann bottleneck. Hence, there is a great engineering motivation towards realising alternative methods to perform the computation on more efficient, environmentally-friendly and low-powered hardware. According to \citet{Strubell_Ganesh_McCallum_2019} \cite{Strubell_Ganesh_McCallum_2019}, it was measured that the carbon footprint to train a \acs{BERT} model is comparable to a trans-American airplane flight. To combat this, there has been significant research work looking into computation-in-memory architectures which performs the computations directly at the memory location itself. In particular, the implementation of a memristor \ac{CBA} architecture to do computation in the analog domain is a promising pathway which will be the focus in this thesis.

\newpage

\section{Research Objective}
The objective of this thesis is to explore how might we make use of the memristor \acf{CBA} with supporting circuitry to perform operation for neural networks like \acf{MAC} and activation function for feedforward \acfp{ANN}. The thesis will also look at the analog noise in the circuit as it will affect the feasibility of scaling up the \acp{CBA} for larger \acp{ANN} and the performance of well-known architectures such as for MNIST classification.

\section{Thesis Synopsis}

\noindent
The rest of this thesis is organized as follows:

\begin{itemize}
  \item
  In the \nameref{ch:introduction}, an overview of the background issue is introduced and the main contribution to the topic is explained through the research objectives.
  \item
  The \nameref{ch:background} chapter provides an introduction to the physical properties of the hardware device that is of interest to be used throughout this project.
  \item
  The \nameref{ch:methodology} chapter explains the different considerations and proposes hardware architecture designs to tackle it.
  \item
  In the \nameref{ch:framework} chapter, the simulation stack is built with the proposed hardware design mapped onto the backend for hardware verification
  \item
  The \nameref{ch:results} chapter demonstrates the operations and principles of the final hardware accelerator design.
  \item
  Lastly, the \nameref{ch:conclusion} chapter summarises the contributions of thesis, learning outcomes and identifies areas of future research.
\end{itemize}